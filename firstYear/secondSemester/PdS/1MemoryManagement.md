# 1 - Memory management

## Background
Usually, a program is on disk as a binary executable file. When  we have to run the program, it is transfered from disk to main memory, within a process, to be eligible for execution of the CPU. 

(As we know, CPU has direct access to main memory and registers, so it's very important to transfer the code from memory to more accessable point for the CPU)

## Problems related to management of memory
In this phase, there are problems related to:
- Space, how much data has to be transfered;
- Speed of loading and storing data;
- Dealing with a lot of processes, each of them with theri data and information that has to be managed indipendently.

## Protection
Another important property is protection, which ensure a process to access only to addresses within its address space and to prevent illegal operation. 

Protection of process's address space is perfomed by using registers called: 
- **base**, which specifies the smallest legal physical memory address;
- **limit** specifies the size of the range. Added to base value, it identifies the biggest legal physical memory address.

In particular cases (see later run time binding), the computations of the address legacy of a certain process is performed by a unit of the CPU, the **Memory Management Unit**, that is an hardware module that guarantee speed. 

<add image slide 8 and 7>


## Address  binding
The addresses in the source code are generally _symbolic_, so the compiler tipically binds these addresses to _relocatable_ addresses.
The address binding is the process of assigning (mapping) a memory address to a program (or a process) at the time of execution. 

### Stages of running programs
Running software programs implies three stages:
- compile time, when the source code of a program is convertedn into machine code;
- load time, when the machine code is loaded into memory (disk);
- Run time, when the code is transfered from disk to main memory and the program is executed.

Address binding can be perfomed in any of the stages, producing different results:
- at compile time, the source code already refers to physical address, so the binding generates _absolute code_. This implies that by changing some allocation in the code, all the other address must be changed;
- at load time, the compiler generates the relocatable code. When this code is loaded into memory, the binding od physical memory is performed.
- at execution time, binsing is performed only when the CPU is available to execute code. By this time, all the assignments are made.

## Definitions of addresses and properties
- **Logical address** (or virtual address) is generated by the CPU;
- **Physical address** is address seen by memory unit. 

Performing binding at compile or load time implies that physical and logical address is the same, while at execution time, binding results in different spaces:
- Logical address space contains all the logical address generated by a program;
- Physical address space contains all the physical ones.
The run-time mapping is made by the MMU.

### Memory Management Unit
The base register is renamed as **relocation register** and its value is added to every address generated by a process when it is sent to memory (physical)

<add image slide 15>

## Loading data of a program
when program code is loaded into memory, how much data has to be transfered? 
We know the entire program must be in memory in order to be executed. So, the **dynamic loading** loads all the libraries or modules into memory at run time, with the intention of load only necessary components when needed (efficiency) and speed up program (by reduce memory allocation).

We distinguish two types of linking:
- static linking, that combine libraries and program code into the binary program image;
- dynamic linked libraries (DLL) that link libraries to user program when they have to be executed. The advantages are shared resources, enhance modularity and reduce memory usage.

## Types of allocation
Main memory stores operating system and user processes. They are placed into two different partitions:
- Low memory or high memory for OS processes;
- Resising space for user processes. This can be managed in two ways:
  - we use the first available space eligible for processes size (<span style="color:purple">method 1</span>);
  - divide into partitions the space and place the processes where it fits (<span style="color:purple">method 2</span>).

### Contiguous allocation
#### Contiguous memory allocation
Each process is contained in a single section of memory that is contiguous to the section cointaing the next process.

<add image slide 19>

This means that a process must wait if there isn't enough space after the previous one.

Here, the relocation registers are used to protect processes from each other. 
<add image of slide 20>

### Variable partition
Assigning processes to variably size partitions where each partition may contain exactly one process. 
So, initially, there is a large block because memory for user processes is available. When a process terminates, it release the memory and might create a **hole** that can be large enough to fit an arriving process.

The dynamic storage-allocation problem refers to the search for a hole (understood as space available) large enough to contains the arriving process.
There are three different approaches:
- **first-fit** allocate the first hole that is big enough;
- **best-fit** allocate the smallest hole big enough. So, it must search the entire list (unless it's ordered) but produces the smallest lefover hole;
- **worst-fit** allocate the largest hole in order to leave a big hole that might be more useful than the smallest leftover. 
First and best fit are better than the worst fit.

### Fragmentation
The phenomenon in which there's available space but is not contiguous (due to the terminated processes), so it can't be used. We distinguish two types of fragmentation:
- External, (result from <span style="color:purple">method 1</span>), when the sum of remaining space satisfies the request, but is not contiguous;
- Internal, (result from <span style="color:purple">method 2</span>), when the sum of residing space from each partition can (even larger) satisfy the request, but the process can be divided into pieces.

This is not an ideal situation, because we want to use as many memory as possible and to ensure that processes are executed in the least time. 
Let's the solutions.

#### Compaction
Periodically, CPU moves all the processes together in one large available block, with the idea to create a contiguous space in which new processes can be executed. This solution is possible only if relocation is dynamic and done at execution time.
<span style="color:red">Update periodically all the base registers of each processes; the CPU time is used for making this operation</span>.

#### Paging
Solution which allows the logic address space of a process to **not be contiguous**. <span style="color:DarkGreen">Avoids external fragmentation and needs for compaction</span>.

Applying paging solution means to divide:
- logical memory into **fixed-size blocks** called **<span style="color:DarkOrange">pages</span>**;
- physical memory into blocks of the **same size** (it is not ensured that the number of blocks is equal to the the numbero of pages) called **<span style="color:DarkOrange">frames</span>**. 

Size is a power of 2 and depends on the computer architecture.

In this way, even if the space is not contiguous, processes can be executed by **loading pages into the available memory frames** (we can image frames and pages as rectangles not contiguous, in different position).

##### Address Translation Scheme
With this approach, it's necessary to find another method to identify where all the pages of a process are mapped into the physical memory. For this reason, a logical address is divided into:
- **page number(p)**, used as index to identify base address of each page frame. This information is retrieved by the page table;
- **page offset(o)**, used to identify the location in the frame being referenced.

So, The MMU uses a support table called **page table**, which contains the frame (so the base address) corresponding to the page number.
Combining base address of the frame and page offset, the physical memory address is obtained.

![Schermata del 2024-03-05 16-36-55](https://i.imgur.com/fYH7NPF.png)
